{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a895dee1-48bf-4071-9e92-7ad7fed8068a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#task1\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "\n",
    "url = \"https://www.baraasallout.com/test.html\"\n",
    "response = requests.get(url)\n",
    "website = BeautifulSoup(response.text,'html.parser')\n",
    "\n",
    "\n",
    "headings = []\n",
    "for heading in website.find_all(['h1', 'h2']):\n",
    "    headings.append(heading.get_text().strip())\n",
    "\n",
    "paragraphs = []\n",
    "for paragraph in website.find_all(['p']):\n",
    "    paragraphs.append(paragraph.get_text().strip())\n",
    "\n",
    "listeditems =[]\n",
    "for lists in website.find_all(['li']):\n",
    "    listeditems.append(lists.get_text().strip())\n",
    "    \n",
    "data = []\n",
    "\n",
    "for heading in headings:\n",
    "    data.append(['Heading', heading])\n",
    "\n",
    "\n",
    "for paragraph in paragraphs:\n",
    "    data.append(['Paragraph', paragraph])\n",
    "\n",
    "for points in listeditems:\n",
    "    data.append(['Listed items',points])\n",
    "\n",
    "\n",
    "\n",
    "with open('Extracting.csv','w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Type', 'Content']) \n",
    "    writer.writerows(data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "46dc1eb8-7b8b-4385-a56b-3a97c87ba8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#task2\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "url = \"https://www.baraasallout.com/test.html\"\n",
    "response = requests.get(url)\n",
    "website = BeautifulSoup(response.content,'html.parser')\n",
    "\n",
    "Tables = website.find_all('table')\n",
    "rows = website.find_all('tr')\n",
    "\n",
    "tabledata=[]\n",
    "\n",
    "for table in Tables:\n",
    "    rows = table.find_all('tr')\n",
    " \n",
    "    for row in rows:\n",
    "        columns = row.find_all(['td', 'th'])\n",
    "        \n",
    "        columns = [col.text.strip() for col in columns]\n",
    "\n",
    "        tabledata.append(columns)\n",
    "\n",
    "with open('Table.csv', mode='w', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerows(tabledata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "47a6f17e-693c-4b69-9c5f-650a0aad4439",
   "metadata": {},
   "outputs": [],
   "source": [
    "#task3\n",
    "import json\n",
    "product_info = []\n",
    "#<div style=\"display: flex; justify-content: space-around; margin-top: 20px;\">\n",
    "products = soup.select(\"div[style*='display: flex;'] > div\")\n",
    "\n",
    "for c in products:\n",
    "    title = c.find(\"strong\").text.strip() if c.find(\"strong\") else \"\"\n",
    "    price = c.find(\"p\", style=\"color: green;\").text.strip() if c.find(\"p\", style=\"color: green;\") else \"\"\n",
    "    stock = c.find_all(\"p\")[2].text.strip() if len(c.find_all(\"p\")) > 2 else \"\"\n",
    "    button = c.find(\"button\").text.strip() if c.find(\"button\") else \"\"\n",
    "\n",
    "    product_info.append({\n",
    "        \"Book Title\": title,\n",
    "        \"Price\": price,\n",
    "        \"Stock Availability\": stock,\n",
    "        \"Button Text\": button\n",
    "    })\n",
    "\n",
    "with open(\"Product_Information.json\", \"w\", encoding=\"utf-8\") as jsonfile:\n",
    "    json.dump(product_info, jsonfile, indent=4)\n",
    "products = soup.select(\"div[style*='display: flex;'] > div\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "94b724d5-a0ec-4308-97a2-723c0ce16f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#task4\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "url = \"https://www.baraasallout.com/test.html\"\n",
    "\n",
    "response = requests.get(url)\n",
    "\n",
    "website = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "form_details = []\n",
    "\n",
    "forms = website.find_all('form')\n",
    "\n",
    "for form in forms:\n",
    "    form_info = {\n",
    "        'action': form.get('action', 'Not specified'),\n",
    "        'method': form.get('method', 'Not specified'),\n",
    "        'inputs': []\n",
    "    }\n",
    "\n",
    "    inputs = form.find_all('input')\n",
    "\n",
    "    for input_field in inputs:\n",
    "        field_name = input_field.get('name', 'No name attribute')\n",
    "        input_type = input_field.get('type', 'text')  # Default to 'text' if no type is specified\n",
    "        default_value = input_field.get('value', 'No default value')  # If no value, use a placeholder\n",
    "\n",
    "        form_info['inputs'].append({\n",
    "            'field_name': field_name,\n",
    "            'input_type': input_type,\n",
    "            'default_value': default_value\n",
    "        })\n",
    "\n",
    "    form_details.append(form_info)\n",
    "\n",
    "with open('FormDetails.json', 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(form_details, json_file, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9c05d967-4bc3-4808-9ad6-627a3cd5224c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#task5\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "url = \"https://www.baraasallout.com/test.html\"\n",
    "response = requests.get(url)\n",
    "\n",
    "website = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "links_and_media = {\n",
    "    \"hyperlinks\": [],\n",
    "    \"videos\": []\n",
    "}\n",
    "\n",
    "for a_tag in website.find_all('a', href=True): \n",
    "    hyperlink = a_tag['href'] \n",
    "    links_and_media['hyperlinks'].append(hyperlink)\n",
    "\n",
    "for iframe_tag in website.find_all('iframe', src=True): \n",
    "    video_link = iframe_tag['src']\n",
    "    links_and_media['videos'].append(video_link)\n",
    "\n",
    "with open('LinksAndMedia.json', 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(links_and_media, json_file, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "25b6165d-a496-415a-b7ce-4028dd6253a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#task6 \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "\n",
    "url = \"https://www.baraasallout.com/test.html\"\n",
    "response = requests.get(url)\n",
    "\n",
    "website = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "featured_products = []\n",
    "featured_section = website.find(\"div\", class_=\"products\")\n",
    "\n",
    "if featured_section:\n",
    "    product_cards = featured_section.find_all(\"div\", class_=\"product-card\")\n",
    "    for c in product_cards:\n",
    "        product_id = c.get(\"data-id\", \"\")\n",
    "        name = c.find(\"p\", class_=\"name\").text.strip() if c.find(\"p\", class_=\"name\") else \"\"\n",
    "        price = c.find(\"p\", class_=\"price\", style=\"display: none;\").text.strip() if c.find(\"p\", class_=\"price\", style=\"display: none;\") else \"\"\n",
    "        colors = c.find(\"p\", class_=\"colors\").text.strip() if c.find(\"p\", class_=\"colors\") else \"\"\n",
    "\n",
    "        featured_products.append({\n",
    "            \"id\": product_id,\n",
    "            \"name\": name,\n",
    "            \"price\": price,\n",
    "            \"colors\": colors\n",
    "        })\n",
    "with open(\"Featured_Products.json\", \"w\", encoding=\"utf-8\") as jsonfile:\n",
    "    json.dump(featured_products, jsonfile, indent=4)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381ee79f-db73-417e-b92d-f935b26e45d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
